---
title: "PracticalMachineLearning-Project"
author: "Camille Gozun"
date: "September 30, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(caret)
library(rpart)
library(randomForest)
library(rattle)
```

## Overview

Using Supervised Machine Learning to predict the manner in which people did their exercise through data collected from wearables. 

These wearables collect large amount of data about personal activity to quantify how much of a particular activity people do, but rarely quantify how well people do it.

The objective of this project is to exercise the learnings from the Practical Machine Learning course.

### Data Characteristics

A variable "classe" is to be used to quantify how well people do their activities tracked by the wearables. 

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. 

Source: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

###Study

Load both train and test data. Columns mostly Na's are removed from both data sets. 
```{r}
training.d <- read.csv("C:\\Users\\tomask\\OneDrive - Hewlett Packard Enterprise\\A&DM R\\pml-training.csv", na.strings = c("NA",""))
testing.d <- read.csv("C:\\Users\\tomask\\OneDrive - Hewlett Packard Enterprise\\A&DM R\\pml-testing.csv",na.strings = c("NA",""))
training.d <- training.d[,-1]
testing.d <- testing.d[,-1]
#remove columns mostly NA's or blanks
dropcols <- c("kurtosis_roll_belt","kurtosis_picth_belt","kurtosis_yaw_belt","skewness_roll_belt","skewness_roll_belt.1","skewness_yaw_belt","max_roll_belt","max_picth_belt","max_yaw_belt","min_roll_belt","min_pitch_belt","min_yaw_belt","amplitude_roll_belt","amplitude_pitch_belt","amplitude_yaw_belt","var_total_accel_belt","avg_roll_belt","stddev_roll_belt","var_roll_belt","avg_pitch_belt","stddev_pitch_belt","var_pitch_belt","avg_yaw_belt","stddev_yaw_belt","var_yaw_belt","var_accel_arm","avg_roll_arm","stddev_roll_arm","var_roll_arm","avg_pitch_arm","stddev_pitch_arm","var_pitch_arm","avg_yaw_arm","stddev_yaw_arm","var_yaw_arm","kurtosis_roll_arm","kurtosis_picth_arm","kurtosis_yaw_arm","skewness_roll_arm","skewness_pitch_arm","skewness_yaw_arm","max_roll_arm","max_picth_arm","max_yaw_arm","min_roll_arm","min_pitch_arm","min_yaw_arm","amplitude_roll_arm","amplitude_pitch_arm","amplitude_yaw_arm","kurtosis_roll_dumbbell","kurtosis_picth_dumbbell","kurtosis_yaw_dumbbell","skewness_roll_dumbbell","skewness_pitch_dumbbell","skewness_yaw_dumbbell","max_roll_dumbbell","max_picth_dumbbell","max_yaw_dumbbell","min_roll_dumbbell","min_pitch_dumbbell","min_yaw_dumbbell","amplitude_roll_dumbbell","amplitude_pitch_dumbbell","amplitude_yaw_dumbbell","var_accel_dumbbell","avg_roll_dumbbell","stddev_roll_dumbbell","var_roll_dumbbell","avg_pitch_dumbbell","stddev_pitch_dumbbell","var_pitch_dumbbell","avg_yaw_dumbbell","stddev_yaw_dumbbell","var_yaw_dumbbell","kurtosis_roll_forearm","kurtosis_picth_forearm","kurtosis_yaw_forearm","skewness_roll_forearm","skewness_pitch_forearm","skewness_yaw_forearm","max_roll_forearm","max_picth_forearm","max_yaw_forearm","min_roll_forearm","min_pitch_forearm","min_yaw_forearm","amplitude_roll_forearm","amplitude_pitch_forearm","amplitude_yaw_forearm","var_accel_forearm","avg_roll_forearm","stddev_roll_forearm","var_roll_forearm","avg_pitch_forearm","stddev_pitch_forearm","var_pitch_forearm","avg_yaw_forearm","stddev_yaw_forearm","var_yaw_forearm")
training.d1 <- training.d[ , !(names(training.d) %in% dropcols)]
testing.d1 <- testing.d[ , !(names(testing.d) %in% dropcols)]
```

###Compare CART and Random Forest

***Fit a model using CART**

Train data set is split into train and validation sets.

```{r}
require(caret)
set.seed(13579)
#creating partition
inTrain <- createDataPartition(y = training.d1$classe, p=0.6, list = FALSE)
training.dFin <- training.d1[inTrain,]
validation.dFin <- training.d1[-inTrain,]

modFit <- train(classe ~. , method = "rpart", data = training.dFin)

print(modFit$finalModel)
#plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
#text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)

```

Validate the model to ensure that we are not overfitting
```{r}
train.cart <- predict(modFit, newdata = training.dFin)
table(train.cart,training.dFin$classe)
#Misclassification rate = (530+1182+1097+352+716+1214+189+1001+9)/11776 = 10501/11776 = .5341
```
Misclassifcation rate is 53% which means more opportunities to tune the model.

Test model using validation data
```{r}
validate.cart <- predict(modFit, newdata = validation.dFin)
table(validate.cart,validation.dFin$classe)
#Misclassification rate = (374+801+717+242+476+810+119+667+5)/7846 = .5367
```
Misclassification rate is 54%. What we see here is that the misclassifcation rate to be really close to each other. Hence, we see a stable CART model in this study (as per further research).

CART model gave decent result in stability, however very low in accuracy.

Source: https://www.analyticsvidhya.com/blog/2014/06/comparing-cart-random-forest-1/

***Fit a model using Random Forest**
```{r}
require(randomForest)
modFit.rf <- train(classe ~. , method = "rf", data = training.dFin) #trControl=trainControl(method="cv",number=5), prox=TRUE, allowParallel=TRUE)
print(modFit.rf)
```
Model has 99.74% accuracy. There are opportunities to tune this model as we might be overfitting.

Validate the model with train data to ensure that we are not overfitting
```{r}
train.rf <- predict(modFit.rf,newdata = training.dFin)
table(train.rf,training.dFin$classe)
```

Test model with validation data
```{r}
validate.rf <- predict(modFit.rf,newdata = validation.dFin)
table(validate.rf,validation.dFin$classe)
```

Lastly, predicting the test data with our final model.

###predict with testing data
```{r}
pred.cart<-predict(modFit.rf,newdata=testing.d1)
print(pred.cart)
```

